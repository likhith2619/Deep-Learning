# -*- coding: utf-8 -*-
"""Music Generation Using RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13et7015LQ5aU0FeTViQ3PnCdu8jhpCF9
"""

!pip install pretty_midi
!sudo apt install -y fluidsynth
!pip install --upgrade pyfluidsynth

import numpy as np
import tensorflow as tf
import pandas as pd
import collections
import fluidsynth
import glob
import pretty_midi
from IPython import display
from typing import Dict, List, Optional, Sequence, Tuple



from google.colab import files
uploaded = files.upload()

!unzip '/content/Dataset-Music-Generation-Using-RNN.zip' -d '/content/music-midi-dataset/'

!ls /content/music-midi-dataset/

sampling_rate = 44100

def display_audio(pm, seconds=30):
	waveform = pm.fluidsynth(fs=sampling_rate)
  # Take a sample of the generated waveform to mitigate kernel resets
	waveform_short = waveform[:seconds*sampling_rate]
	return display.Audio(waveform_short, rate=sampling_rate)

pm = pretty_midi.PrettyMIDI()
# Create an instrument instance and add it to the PrettyMIDI object
instrument = pretty_midi.Instrument(program=0, is_drum=False, name='acoustic grand piano')
pm.instruments.append(instrument)
print(pm.instruments)
instrument = pm.instruments[0]

# This code is modified by Susobhan Akhuli

import os
import pretty_midi
import collections
import numpy as np
import pandas as pd

def midi_to_notes(midi_file):
    # Get the absolute path to the MIDI file
    midi_file_path = os.path.join('/content/music-midi-dataset/', midi_file)
    pm = pretty_midi.PrettyMIDI(midi_file_path)
    instrument = pm.instruments[0]
    notes = collections.defaultdict(list)
    sorted_notes = sorted(instrument.notes, key=lambda note: note.start)
    prev_start = sorted_notes[0].start

    for note in sorted_notes:
        start = note.start
        end = note.end
        notes["pitch"].append(note.pitch)
        notes["start"].append(start)
        notes["end"].append(end)
        notes["step"].append(start - prev_start)
        notes["duration"].append(end - start)
        prev_start = start

    return pd.DataFrame({name: np.array(value) for name, value in notes.items()})

# Assuming your midi files are in the 'music-midi-dataset' directory
raw_notes = midi_to_notes('Dataset - Music Generation Using RNN.mid')
note_names = np.vectorize(pretty_midi.note_number_to_name)
sample_note_names = note_names(raw_notes["pitch"])

# This code is modified by Susobhan Akhuli

def notes_to_midi(
  notes: pd.DataFrame,
  out_file: str,
  instrument_name: str,
  velocity: int = 100,  # note loudness
) -> pretty_midi.PrettyMIDI:

  pm = pretty_midi.PrettyMIDI()
  instrument = pretty_midi.Instrument(
      program=pretty_midi.instrument_name_to_program(
          instrument_name))

  prev_start = 0
  for i, note in notes.iterrows():
    start = float(prev_start + note['step'])
    end = float(start + note['duration'])
    note = pretty_midi.Note(
        velocity=velocity,
        pitch=int(note['pitch']),
        start=start,
        end=end,
    )
    instrument.notes.append(note)
    prev_start = start

  pm.instruments.append(instrument)
  pm.write(out_file)
  return pm

import glob
import pandas as pd
import tensorflow as tf

num_files = 5
all_notes = []
filenames = glob.glob('/content/music-midi-dataset/*.mid')  # Ensure the correct path to MIDI files

# Check if filenames is not empty
if not filenames:
    print("No MIDI files found in the specified directory.")

for f in filenames[:num_files]:
    try:
        notes = midi_to_notes(f)
        if not notes.empty:  # Check if notes are not empty
            all_notes.append(notes)
        else:
            print(f"Warning: No notes extracted from {f}")
    except Exception as e:
        print(f"Error processing {f}: {e}")

# Ensure all_notes is not empty before concatenating
if all_notes:
    all_notes = pd.concat(all_notes)
    print(all_notes)
else:
    print("No notes data to concatenate.")

key_order = ["pitch", "step", "duration"]
train_notes = np.stack([all_notes[key] for key in key_order], axis=1)

# Check the shape of train_notes before creating the TensorFlow dataset
print("Train notes shape:", train_notes.shape)

notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)
print(notes_ds.element_spec)

import tensorflow as tf
import numpy as np

seq_length = 20
vocab_size = 128

def create_sequences(dataset, seq_length, vocab_size=128):
    sequences = []
    targets = []
    num_seq = dataset.shape[0] - seq_length  # Update from train_notes to dataset
    for i in range(num_seq):
        sequence = dataset[i:i+seq_length - 1,:] / [vocab_size, 1 ,1]
        target =  dataset[i+seq_length] / vocab_size
        sequences.append(sequence)
        targets.append(target)

    sequences = np.array(sequences)
    targets = np.array(targets)

    print(sequences.shape, targets.shape)

    # Fixing the dictionary syntax error
    dataset = tf.data.Dataset.from_tensor_slices((sequences, {"pitch": targets[:,0], "step": targets[:,1], "duration": targets[:,2]}))
    return dataset

# Assuming notes_ds is your dataset
seq_ds = create_sequences(train_notes, seq_length=21, vocab_size=vocab_size)

batch_size = 64
buffer_size = 5000

train_ds = seq_ds.shuffle(buffer_size).batch(batch_size)
print(train_ds.element_spec)

import tensorflow as tf

# Set learning rate and sequence length
learning_rate = 0.005
seq_length = 20

# Define the model architecture
input_data = tf.keras.Input(shape=(seq_length, 3))
x = tf.keras.layers.LSTM(128)(input_data)
outputs = {
    "pitch": tf.keras.layers.Dense(64, name="pitch")(x),
    "step": tf.keras.layers.Dense(1, name="step")(x),
    "duration": tf.keras.layers.Dense(1, name="duration")(x),
}

model = tf.keras.Model(input_data, outputs)

# Define loss functions
loss = {
    "pitch": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    "step": tf.keras.losses.MeanSquaredError(),
    "duration": tf.keras.losses.MeanSquaredError(),
}

# Set optimizer
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)

# Compile the model
model.compile(loss=loss, loss_weights={
        "pitch": 0.05,
        "step": 1.0,
        "duration": 1.0,
    }, optimizer=optimizer)

# Model summary
model.summary()

# Train the model
model.fit(train_ds, epochs=10)

# Make predictions on the training dataset
hist = model.predict(train_ds)

# Print the shape of the "duration" output from the predictions
print(hist["duration"].shape)

def predict_next_note(notes, keras_model, temperature):
    assert temperature > 0
    inputs = np.expand_dims(notes, 0)
    predictions = keras_model.predict(inputs)

    pitch_logits = predictions['pitch']
    step = predictions["step"]
    duration = predictions["duration"]

    # Adjust pitch logits for temperature
    pitch_logits /= temperature

    # Sample from the logits to predict pitch
    pitch = tf.random.categorical(pitch_logits, num_samples=1)
    pitch = tf.squeeze(pitch, axis=-1)

    # Squeeze the step and duration for prediction
    duration = tf.squeeze(duration, axis=-1)
    step = tf.squeeze(step, axis=-1)

    # Make sure step and duration are non-negative
    step = tf.maximum(0, step)
    duration = tf.maximum(0, duration)

    return int(pitch), float(step), float(duration)


temperature = 2.0
num_predictions = 1200

# Sample notes reshaped as in the training process
sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)

# The initial sequence of notes and pitch is normalized similar to training sequences
input_notes = sample_notes[:seq_length] / np.array([vocab_size, 1, 1])

generated_notes = []
prev_start = 0

for _ in range(num_predictions):
    pitch, step, duration = predict_next_note(input_notes, model, temperature)
    start = prev_start + step
    end = start + duration

    # Append generated note (pitch, step, duration, start, end)
    input_note = (pitch, step, duration)
    generated_notes.append((*input_note, start, end))

    # Update the input sequence for the next prediction
    input_notes = np.delete(input_notes, 0, axis=0)
    input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)

    prev_start = start

# Convert generated notes to DataFrame for easy processing
generated_notes = pd.DataFrame(
    generated_notes, columns=(*key_order, 'start', 'end')
)

print(generated_notes)

out_file = 'gfgmusicgnerate.mid'
instrument_name= pretty_midi.program_to_instrument_name(instrument.program)
out_pm = notes_to_midi(
    generated_notes, out_file=out_file, instrument_name=instrument_name)
display_audio(out_pm , 500)

